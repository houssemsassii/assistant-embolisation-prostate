# Configuration pour l'assistant médical RAG
# Copiez ce fichier vers .env et remplissez vos clés API

# ============================================
# CLÉS API LLM (choisissez-en une)
# ============================================

# Option 1: OpenAI (recommandé pour la production)
# OPENAI_API_KEY=sk-...

# Option 2: Groq (rapide et gratuit pour le développement)
# GROQ_API_KEY=gsk_...

# ============================================
# CONFIGURATION DU MODÈLE
# ============================================

# Provider à utiliser: "openai" ou "groq"
LLM_PROVIDER=groq

# Modèle à utiliser
# Pour OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo
# Pour Groq: llama-3.1-70b-versatile, mixtral-8x7b-32768
MODEL_NAME=llama-3.1-70b-versatile

# Température (0.0 = déterministe, 1.0 = créatif)
# Pour usage médical, gardez entre 0.0 et 0.3
TEMPERATURE=0.1

# ============================================
# CONFIGURATION RAG
# ============================================

# Nombre de chunks à récupérer pour chaque question
TOP_K_RETRIEVAL=4

# Taille des chunks de texte (en tokens approximatifs)
CHUNK_SIZE=500

# Chevauchement entre chunks
CHUNK_OVERLAP=50
